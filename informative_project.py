# -*- coding: utf-8 -*-
"""Informative Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1skhqvJypQjVoGd47bm3yOxsSHlbRibS3

# Import Required Libraries
"""

import pandas as pd
import numpy as np
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

"""# Load Data"""

reviews_df = pd.read_csv("user_reviews.csv")
apps_df = pd.read_csv("apps.csv")

"""# Data Preprocessing for Reviews"""

reviews_df.dropna(subset=['Translated_Review', 'Sentiment'], inplace=True)
reviews_df = reviews_df[['Translated_Review', 'Sentiment']]

"""# EDA"""

print("User Reviews Dataset Overview:")
print(reviews_df.info())

print("\nSentiment Distribution:")
print(reviews_df['Sentiment'].value_counts())

# Basic EDA for apps.csv
print("\nApps Dataset Overview:")
print(apps_df.info())

print("\nTop Categories by App Count:")
print(apps_df['Category'].value_counts().head())

# Visualizations
# 1. Sentiment Distribution
plt.figure(figsize=(8, 5))
sns.countplot(data=reviews_df, x='Sentiment', palette='viridis')
plt.title('Sentiment Distribution')
plt.show()

# 2. Top 10 App Categories
plt.figure(figsize=(8, 5))
apps_df['Category'].value_counts().head(10).plot(kind='bar', color='skyblue')
plt.title('Top 10 App Categories')
plt.ylabel('Count')
plt.xlabel('Category')
plt.show()

# 3. App Ratings Distribution
plt.figure(figsize=(8, 5))
sns.histplot(apps_df['Rating'], kde=True, bins=20, color='orange')
plt.title('App Ratings Distribution')
plt.xlabel('Rating')
plt.show()

# 4. App Installs Distribution (log scale for better visualization)
plt.figure(figsize=(8, 5))
apps_df['Installs'] = apps_df['Installs'].str.replace('[+,]', '', regex=True).astype(int)
sns.histplot(apps_df['Installs'], kde=True, bins=20, color='green', log_scale=True)
plt.title('App Installs Distribution (Log Scale)')
plt.xlabel('Installs')
plt.show()

import nltk
nltk.download('punkt_tab')

"""# Text Preprocessing"""

# Text Preprocessing Function
def preprocess_text(text):
    tokens = word_tokenize(text.lower())
    tokens = [word for word in tokens if word.isalnum()]
    tokens = [word for word in tokens if word not in stopwords.words('english')]
    return " ".join(tokens)

# Data Preprocessing for Reviews
# Removing NaN values in the Sentiment column
reviews_df.dropna(subset=['Translated_Review', 'Sentiment'], inplace=True)

# Ensure the Sentiment column contains no NaN values
reviews_df = reviews_df[reviews_df['Sentiment'].notna()]

# Encode Sentiments (Mapping Positive to 1, Negative to 0, and filtering only these two classes)
reviews_df = reviews_df[reviews_df['Sentiment'].isin(['Positive', 'Negative'])]
reviews_df['Sentiment_Encoded'] = reviews_df['Sentiment'].map({'Positive': 1, 'Negative': 0})

# Process the reviews
reviews_df['Processed_Review'] = reviews_df['Translated_Review'].apply(preprocess_text)

"""# Train-Test Split"""

# Split Data
X = reviews_df['Processed_Review']
y = reviews_df['Sentiment_Encoded']

# Convert Text to Features using TF-IDF Vectorizer
tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf.fit_transform(X)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

"""# Random Forest Model"""

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

rf_y_pred = rf_classifier.predict(X_test)

print("Confusion Matrix:")
rf_cm = confusion_matrix(y_test, rf_y_pred)
print(rf_cm)

print("\nClassification Report:")
print(classification_report(y_test, rf_y_pred))
print("\nAccuracy Score:", accuracy_score(y_test, rf_y_pred))

# Visualize Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap(rf_cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix - Random Forest")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

"""# Logistic Regression Classifier"""

lr_classifier = LogisticRegression(max_iter=200, random_state=42)
lr_classifier.fit(X_train, y_train)

lr_y_pred = lr_classifier.predict(X_test)

print("Confusion Matrix:")
lr_cm = confusion_matrix(y_test, lr_y_pred)
print(lr_cm)

print("\nClassification Report:")
print(classification_report(y_test, lr_y_pred))

print("\nAccuracy Score:", accuracy_score(y_test, lr_y_pred))

# Visualize Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap(lr_cm, annot=True, fmt="d", cmap="Greens")
plt.title("Confusion Matrix - Logistic Regression")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

"""# Support Vector Classifier (SVC)"""

print("\nSupport Vector Classifier")
svc_classifier = SVC(kernel="linear", random_state=42)
svc_classifier.fit(X_train, y_train)

svc_y_pred = svc_classifier.predict(X_test)

print("Confusion Matrix:")
svc_cm = confusion_matrix(y_test, svc_y_pred)
print(svc_cm)

print("\nClassification Report:")
print(classification_report(y_test, svc_y_pred))

print("\nAccuracy Score:", accuracy_score(y_test, svc_y_pred))

# Visualize Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap(svc_cm, annot=True, fmt="d", cmap="Oranges")
plt.title("Confusion Matrix - Support Vector Classifier")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

"""# Summarization using Grouped Analysis"""

summary = reviews_df.groupby('Sentiment')['Translated_Review'].apply(lambda x: ' '.join(x))
print("\nSummarized Reviews:")
print(summary)

"""# Comparison of Model Accuracies"""

# Accuracy Scores of Models
rf_accuracy = accuracy_score(y_test, rf_y_pred)
lr_accuracy = accuracy_score(y_test, lr_y_pred)
svc_accuracy = accuracy_score(y_test, svc_y_pred)

# Bar Plot for Model Accuracies
model_names = ["Random Forest", "Logistic Regression", "SVC"]
accuracies = [rf_accuracy, lr_accuracy, svc_accuracy]

plt.figure(figsize=(8, 6))
sns.barplot(x=model_names, y=accuracies, palette="viridis")
plt.title("Comparison of Model Accuracies")
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.ylim(0, 1)
plt.show()

"""# sentiment for user input text"""

# Function to predict sentiment for user input text
def predict_sentiment(input_text, model):
    # Preprocess the input text
    processed_text = preprocess_text(input_text)
    # Convert to TF-IDF features
    text_tfidf = tfidf.transform([processed_text])
    # Predict sentiment
    prediction = model.predict(text_tfidf)
    # Map prediction back to sentiment label
    sentiment_label = "Positive" if prediction[0] == 1 else "Negative"
    return sentiment_label

# User input section
while True:
    print("\nSentiment Prediction:")
    user_input = input("Enter a review (or type 'exit' to quit): ")
    if user_input.lower() == 'exit':
        print("Exiting Sentiment Prediction.")
        break

    # Display predictions for all three models
    rf_sentiment = predict_sentiment(user_input, rf_classifier)
    lr_sentiment = predict_sentiment(user_input, lr_classifier)
    svc_sentiment = predict_sentiment(user_input, svc_classifier)

    print(f"\nPredicted Sentiment:")
    print(f"Random Forest Classifier: {rf_sentiment}")
    print(f"Logistic Regression: {lr_sentiment}")
    print(f"Support Vector Classifier: {svc_sentiment}")